---
title: "R Notebook"
output: html_notebook
date: 9 November 2020
---


Downloading csv file from Kaggle Data set - https://www.kaggle.com/austinreese/craigslist-carstrucks-data

```{r}
library(dplyr)
library(rpart)
carData <- read.csv("/Users/rebeccahousey/Documents/GitHub/UsedCarRepo/vehicles.csv", header = TRUE, sep = ',' ,na.strings = "", stringsAsFactors = FALSE)

#carData <- read.csv("~/Documents/GitHub/UsedCarRepo/vehicle#s.csv", header = #TRUE, sep = ',' ,na.strings = "", stringsAsFactors = FALSE)
#str(vehicles)
```
Cleaning data (1)
- removing 'cylinders' in cylinders column 
- removing id, url, region_url, county columns, image_url, description, vin (irrelevant)
- removing NAs 
- changing year to age of car
- converting condition to numerical (0 = salvage, 1 = fair, 2 = good, 3 = excellent, 4 = like new, 5 = new)
- converting dometer to numeric 
```{r} 
carData$cylinders <- gsub('cylinders', "", paste(carData$cylinders))
carData <- select(carData, -c(id, url, region_url, county, image_url, description, vin))
carData <- na.omit(carData)
carData[carData == 'NA'] <- NA
carData <- na.omit(carData)
carData %>% mutate(age = 2020-year) %>% select(-year) -> vehicles
carData <- carData[complete.cases(carData),]

carData$condition[carData$condition == 'salvage'] = 0
carData$condition[carData$condition == 'fair'] = 1
carData$condition[carData$condition == 'good'] = 2
carData$condition[carData$condition == 'excellent'] = 3
carData$condition[carData$condition == 'like new'] = 4
carData$condition[carData$condition == 'new'] = 5
str(carData)
```
making condition, odometer numerical values
making categorical data into factors 
```{r}
carData$condition <- as.numeric(as.character(carData$condition))
carData$odometer <- as.numeric(carData$odometer)


categorical <- c("region", "manufacturer", "model", "condition", "cylinders", "fuel", "title_status", "transmission", "drive", "size", "type", "state", "paint_color")
```
Plotting to see correlations between price and other variables
1) There is a high correlation between price and transmission, 
```{r}
library(ggplot2)
ggplot(data = carData, mapping = aes(x = condition, y = price)) + geom_point()
ggplot(data = carData, aes(condition, price)) + geom_jitter(color = "blue", alpha = 0.5) + theme_light() + scale_y_log10()
ggplot(data = carData, aes(paint_color, price)) + geom_jitter(color = "blue", alpha = 0.05) + theme_light() + ylim(4000,100000)
ggplot(data = carData, aes(model, price)) + geom_jitter(color = "blue", alpha = 0.05) + theme_light() + ylim(4000,100000)
```


Splitting up the data 
Training and Testing Data to use 80% training 20% testing
```{r}
split <- sort(sample(nrow(carData), nrow(carData)*.8))
trainingCar <- carData[split,]
testCar <- carData[-split,]

```

```{r}
library(gbm)          # basic implementation

set.seed(123)
# train GBM model
gbm.fit <- gbm(
  formula = price ~ .-region-model,
  distribution = "gaussian",
  data = trainingCar,
  n.trees = 5000,
  interaction.depth = 1,
  shrinkage = 0.001,
  cv.folds = 5,
  n.cores = NULL, # will use all cores by default
  verbose = FALSE
)  

# print results
print(gbm.fit)

#Get MSE and compute RMSE
sqrt(min(gbm.fit$cv.error))

# plot loss function as a result of n trees added to the ensemble
gbm.perf(gbm.fit, method = "cv")

#relative influence graph
par(mar = c(5, 8, 1, 1))
summary(
  gbm.fit, 
  cBars = 31,
  method = relative.influence,
  las = 2
)
```




```{r}
#Classification Tree
library(rpart)

str(trainingCar)

log <- rpart(price ~ region+ year+manufacturer+model +condition+ cylinders + fuel + odometer+ title_status+ transmission+drive+ size+ type +paint_color+ state+lat+ long, data = trainingCar)
```

```{r}
tree_pred = predict(tree_model, newdata=testCar)
SSE <- sum((tree_pred-testCar$price)^2)
SST <- sum(testCar$price, mean(testCar$price)^2)
R_square <- 1- SSE/SST
RMSE <- sqrt(SSE/nrow(carData))
R_square


#getting mean square error
mape <- mean(abs((real_preds$predicteds - real_preds$actuals))/real_preds$actuals)
mse <- mean((testCar$price-pred_value)^2)
mse
```






