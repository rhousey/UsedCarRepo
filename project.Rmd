---
title: "R Notebook"
output: html_notebook
date: 9 November 2020
---


Downloading csv file from Kaggle Data set - https://www.kaggle.com/austinreese/craigslist-carstrucks-data

```{r}
library(dplyr)
library(rpart)
carData <- read.csv("/Users/rebeccahousey/Documents/GitHub/vehicles.csv", header = TRUE, sep = ',' ,na.strings = "", stringsAsFactors = FALSE)

#carData <- read.csv("~/Documents/GitHub/UsedCarRepo/vehicle#s.csv", header = #TRUE, sep = ',' ,na.strings = "", stringsAsFactors = FALSE)
#str(vehicles)
```
Cleaning data (1)
- removing 'cylinders' in cylinders column 
- removing id, url, region_url, county columns, image_url, description, vin (irrelevant)
- removing NAs 
- changing year to age of car
- converting condition to numerical (0 = salvage, 1 = fair, 2 = good, 3 = excellent, 4 = like new, 5 = new)
- converting dometer to numeric 
```{r} 
carData$cylinders <- gsub('cylinders', "", paste(carData$cylinders))
carData <- select(carData, -c(id, url, region_url, county, image_url, description, vin))
carData <- na.omit(carData)
carData[carData == 'NA'] <- NA
carData <- na.omit(carData)
carData %>% mutate(age = 2020-year) %>% select(-year) -> vehicles
carData <- carData[complete.cases(carData),]

carData$condition[carData$condition == 'salvage'] = 0
carData$condition[carData$condition == 'fair'] = 1
carData$condition[carData$condition == 'good'] = 2
carData$condition[carData$condition == 'excellent'] = 3
carData$condition[carData$condition == 'like new'] = 4
carData$condition[carData$condition == 'new'] = 5
categorical <- c("region", "manufacturer", "model", "condition", "cylinders", "fuel", "title_status", "transmission", "drive", "size", "type", "state", "paint_color")
carData[categorical] <- lapply(carData[categorical], factor)
carData$condition <- as.numeric(carData$condition)
carData$odometer <- as.numeric(carData$odometer)
carData$year <- as.numeric(carData$year)
carData$price <- as.numeric(carData$price)


```

```{r}
carData <- carData %>% filter(price != 0)
carData <- carData %>% filter(price != 1)
carData <- carData %>% filter(price != 2)
carData <- carData %>% filter(odometer != 0)
carData <- carData %>% filter(odometer != 1)
carData <- carData %>% filter(odometer != 2)

```




Getting rid of least frequent models that appear in the data 
```{r}
library(plyr)

library(data.table)
nlevels(carData$model)

 setDT(carData)[, if(.N > 40) .SD, by = model]
carData<- carData %>% group_by(model) %>% filter(n() > 40)
```


 
Plotting to see correlations between price and other variables
1) There is a high correlation between price and transmission, 

```{r}
library(ggplot2)
gg <- ggplot(carData, aes(x = odometer, y=price)) + geom_point() + geom_smooth(method = "lm", se = F) + xlim(2000,50000) + ylim(3000,190000)
gg

ggplot(data = carData, aes(condition, price)) + geom_jitter(color = "blue", alpha = 0.5) + theme_light() + ylim(4000,100000)
ggplot(data = carData, aes(paint_color, price)) + geom_jitter(color = "blue", alpha = 0.05) + theme_light() + ylim(4000,100000)
ggplot(data = carData, aes(model, price)) + geom_jitter(color = "blue", alpha = 0.05) + theme_light() + ylim(4000,80000)_coord_flip()
```

```{r}
g <- ggplot(carData, aes(odometer, price))
g + geom_bar(stat="identity", width = 0.5, fill="tomato2") + 
      labs(title="Bar Chart", 
           subtitle="Manufacturer of vehicles", 
           caption="Source: Frequency of Manufacturers from 'mpg' dataset") +
      theme(axis.text.x = element_text(angle=65, vjust=0.6))
```


```{r}
library(ggplot2)
ggplot(carData, aes(x = odometer, y = price))+ylim(4000,100000)+geom_point(alpha = 0.2, size = 2)+xlim(500,400000)

ggplot(carData, aes(x = manufacturer, y = price)) + geom_point(alpha = 0.2, size=2)+ylim(2000,200000)


ggplot(carData, aes(odometer, price)) + geom_line(color = "red") + geom_point(shape = 21, color = "black",fill="#69b3a2", size=3)+ ylim(4000,100000)+xlim(500,400000)+ggtitle("Odometer VS Price")

ggplot(carData, aes(odometer, price)) + geom_histogram(color = "red", alpha = .5)+ ylim(4000,100000)+xlim(500,400000)+ggtitle("Odometer VS Price")
```

Splitting up the data 
Training and Testing Data to use 80% training 20% testing
```{r}
split <- sort(sample(nrow(carData), nrow(carData)*.8))
trainingCar <- carData[split,]
testCar <- carData[-split,]

```

```{r}
library(gbm)          # basic implementation

set.seed(123)
# train GBM model
gbm.fit <- gbm(
  formula = price ~ .-region-model,
  distribution = "gaussian",
  data = trainingCar,
  n.trees = 5000,
  interaction.depth = 1,
  shrinkage = 0.001,
  cv.folds = 5,
  n.cores = NULL, # will use all cores by default
  verbose = FALSE
)  

# print results
print(gbm.fit)

#Get MSE and compute RMSE
sqrt(min(gbm.fit$cv.error))

# plot loss function as a result of n trees added to the ensemble
gbm.perf(gbm.fit, method = "cv")

#relative influence graph
par(mar = c(5, 8, 1, 1))
summary(
  gbm.fit, 
  cBars = 31,
  method = relative.influence,
  las = 2
)
```




```{r}
#Classification Tree
library(rpart)

str(trainingCar)

log <- rpart(price ~ region+ year+manufacturer+model +condition+ cylinders + fuel + odometer+ title_status+ transmission+drive+ size+ type +paint_color+ state+lat+ long, data = trainingCar, method = "class")
```
```{r}
summary(log)

```

```{r}
tree_pred = predict(tree_model, newdata=testCar)
SSE <- sum((tree_pred-testCar$price)^2)
SST <- sum(testCar$price, mean(testCar$price)^2)
R_square <- 1- SSE/SST
RMSE <- sqrt(SSE/nrow(carData))
R_square


#getting mean square error
mape <- mean(abs((real_preds$predicteds - real_preds$actuals))/real_preds$actuals)
mse <- mean((testCar$price-pred_value)^2)
mse
```






